<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>cyl&#39;s blog</title>
  
  
  <link href="https://ysln.github.io/atom.xml" rel="self"/>
  
  <link href="https://ysln.github.io/"/>
  <updated>2021-05-05T02:14:07.066Z</updated>
  <id>https://ysln.github.io/</id>
  
  <author>
    <name>yl.chen</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>spinlock &amp; mutex &amp; futex</title>
    <link href="https://ysln.github.io/2021/05/05/spin-mutex-futex/"/>
    <id>https://ysln.github.io/2021/05/05/spin-mutex-futex/</id>
    <published>2021-05-05T02:25:50.018Z</published>
    <updated>2021-05-05T02:14:07.066Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><strong>参考资料</strong>: </p><ul><li><p><a href="https://www.bilibili.com/video/BV1HN41197Ko?p=10">2021 南京大学 “操作系统：设计与实现” (蒋炎岩)</a></p></li><li><p><a href="https://coolshell.cn/articles/3301.html">JEFF DEAN的STANFORD演讲</a></p></li></ul></blockquote><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在 <a href="https://coolshell.cn/articles/3301.html">CoolShell</a> 上看到一篇文章, Jeff Dean 2010年在斯坦福大学的一场题为”Building Software Systems at Google and Lessons Learned”演讲中, 提到的 <em><strong>Numbers Everyone Should Know</strong></em> :</p><img src="/2021/05/05/spin-mutex-futex/image-20210403200209265.png" alt="image-20210403200209265" style="zoom: 50%;"><blockquote><p>上图中的数据是2010年左右的, 放到现在来说可能不是太精确(而且对不同硬件配置来说也不一样). 但是这些数据本身也不是为了精确的衡量各种延迟, 主要是看一下数据的数量级, 以及不同项之间的纵向的比率. </p><p><a href="http://norvig.com/21-days.html"><strong>Teach Yourself Programming in Ten Years</strong></a> 这篇文章里也提到了这些数据. </p></blockquote><p>上图中的数据最令我震惊的是<code>Mutex lock/unlock</code>居然只要<strong>25ns !</strong> </p><p>但我在许多地方都看到过这样的言论: <em>“加锁操作的开销是昂贵的, 加锁可能导致性能下降”</em>. 所以我一直以为<code>lock/unlock</code>操作开销至少也得几百微秒, 甚至毫秒级. 但上图颠覆了我的认知, 于是, 亲自做个实验验证一下.</p><h2 id="mutex的开销"><a href="#mutex的开销" class="headerlink" title="mutex的开销"></a>mutex的开销</h2><p>测试的代码如下, 只是单纯的在<strong>单线程</strong>程序中进行N次<code>lock/unlock</code>操作, 统计花费的时间:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;time.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;pthread.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> N 100000</span></span><br><span class="line"><span class="keyword">pthread_mutex_t</span> mutex;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    pthread_mutex_init(&amp;mutex, <span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">timespec</span> <span class="title">start</span>;</span></span><br><span class="line">    clock_gettime(CLOCK_REALTIME, &amp;start);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; ++i) &#123;</span><br><span class="line">        pthread_mutex_lock(&amp;mutex);</span><br><span class="line">        pthread_mutex_unlock(&amp;mutex);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">timespec</span> <span class="title">end</span>;</span></span><br><span class="line">    clock_gettime(CLOCK_REALTIME, &amp;end);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> time = (end.tv_sec - <span class="number">1</span> - start.tv_sec) * <span class="number">1000000000</span></span><br><span class="line">                + (end.tv_nsec + <span class="number">1000000000</span> - start.tv_nsec);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Test lock/unlock for [%d] times.\n&quot;</span></span><br><span class="line">            <span class="string">&quot;Total takes [%ld] ns.\n&quot;</span></span><br><span class="line">            <span class="string">&quot;One cycle takes [%ld] ns.\n&quot;</span>, N, time, time / N);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用gcc编译(不优化), 测试的机器的处理器为 “<strong>Intel(R) Core(TM) i5-6300HQ CPU @ 2.30GHz   2.30 GHz</strong>“, 系统为<code>VirtualBox</code>虚拟机上运行的<code>Ubuntu 18.04</code>, 虚拟机配置为两个CPU.</p><p>程序的运行结果如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Test lock&#x2F;unlock for [100000] times.</span><br><span class="line">Total takes [3223049] ns.</span><br><span class="line">One cycle takes [32] ns.</span><br></pre></td></tr></table></figure><p>结果和Jeff Dean提到的数据确实也<strong>基本吻合</strong>, <strong>几十纳秒的数量级</strong>! </p><h2 id="fast-path-amp-slow-path"><a href="#fast-path-amp-slow-path" class="headerlink" title="fast path &amp; slow path"></a>fast path &amp; slow path</h2><p>按理来说, 实验到这里也就结束了, 但是之后在看jyy老师的OS课程时, jyy提到操作系统的两种锁实现: <code>spinlock</code>和<code>mutexlock</code>(姑且叫这个名字).</p><p><code>spinlock</code>只要使用一条原子指令就可以完成, x86平台下提供的<code>lock</code>前缀的指令就可以达到这个目的, 比如<code>lock xchg</code>:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// equal to ==&gt; swap(*addr, newval)</span></span><br><span class="line"><span class="function"><span class="keyword">intptr_t</span> <span class="title">atomic_xchg</span><span class="params">(<span class="keyword">volatile</span> <span class="keyword">intptr_t</span> *addr, <span class="keyword">intptr_t</span> newval)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">intptr_t</span> result;</span><br><span class="line">    <span class="function"><span class="keyword">asm</span> <span class="title">volatile</span> <span class="params">(<span class="string">&quot;lock xchg %0, %1&quot;</span></span></span></span><br><span class="line"><span class="function"><span class="params">                  : <span class="string">&quot;+m&quot;</span>(*addr), <span class="string">&quot;=a&quot;</span>(result)</span></span></span><br><span class="line"><span class="function"><span class="params">                  : <span class="string">&quot;1&quot;</span>(newval)</span></span></span><br><span class="line"><span class="function"><span class="params">                  : <span class="string">&quot;cc&quot;</span>)</span></span>;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">lock</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (atomic_xchg(&amp;lock-&gt;locked, <span class="number">1</span>)) &#123;</span><br><span class="line">        <span class="comment">// wait</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">unlock</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// wake</span></span><br><span class="line">    atomic_xchg(&amp;locked-&gt;locked, <span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因此, <code>spinlock</code>不需要经过系统调用就可以实现线程间的互斥访问共享资源, 众所周知系统调用的开销相对来说是很大的(一般为<strong>微秒级</strong>).</p><p>但是, 在<code>spinlock</code>上的等待的线程不断地执行<code>lock xchg</code>, 白白浪费宝贵的处理器时间.</p><p>一种合理的改进方法是, 当线程获取锁失败时, 不是让它满等待, 而是让操作系统把线程的执行状态改成某个标识, 比如<code>blocking in a lock</code>, 下次操作系统调度线程执行时就不再调度它执行, 直到等待的锁被释放, 才把该线程的状态改成<code>runnable</code>. 姑且把这种锁机制称为<code>mutexlock</code>.</p><p>从上述的描述中可以发现, <code>mutexlock</code>需要操作系统的支持, 也就是说操作系统需要提供一个类似<code>SYS_lock</code>的系统调用接口, 而系统调用的开销较大, 如果<code>POSIX mutex</code>使用这种实现, 我相信<code>lock/unlock</code>的时间肯定不止几十纳秒.</p><p><code>spinlock</code>和<code>mutexlock</code>各有其优劣, 那么能不能结合两种锁各自的优点, 设计一种新的锁机制?</p><p>当然可以! 这背后的思想便是jyy多次提到的 <strong>fast path &amp; slow path</strong> (jyy在讲内存分配的设计时也提到了这种思想).</p><ul><li>fast path: 只需要一条原子指令(比如<code>lock xchg</code>), 上锁成功立即返回.</li><li>slow path: 上锁失败, 调用系统调用, 让操作系统调度其他线程执行(相当于进入睡眠).</li></ul><p>这便是 <strong>Futex(Fast Userspace muTexes)</strong> 的设计思想. 但是使用上面这种方式, <code>unlock</code>时至少也需要一次系统调用, 用来”唤醒”在该锁上<code>blocking</code>的线程, 而如果此时没有其他线程在等待这把锁, 此次系统调用就是多余的. 然而实际使用的<code>Futex</code>的实现中不会有这个问题, 它使用了一些巧妙的设计避免了<code>unlock</code>时不必要的系统调用.</p><h2 id="深入验证"><a href="#深入验证" class="headerlink" title="深入验证"></a>深入验证</h2><p><code>futex</code>是Linux系统提供的系统调用, <code>POSIX mutex</code>就是用<code>futex</code>机制实现的.</p><img src="/2021/05/05/spin-mutex-futex/image-20210403213833104.png" alt="image-20210403213833104" style="zoom: 80%;"><p>下面深入验证一下上文的验证程序是否调用了该系统调用.</p><h3 id="strace"><a href="#strace" class="headerlink" title="strace"></a>strace</h3><p>使用<code>strace</code>来跟踪程序使用的系统调用, 过滤一些输出:</p><img src="/2021/05/05/spin-mutex-futex/image-20210403214635686.png" alt="image-20210403214635686" style="zoom:80%;"><p>可以看到没有调用<code>futex</code>. 会不会是被编译器优化了?</p><p>使用<code>objdump</code>看一下编译生成的 a.out:</p><img src="/2021/05/05/spin-mutex-futex/image-20210403214955744.png" alt="image-20210403214955744" style="zoom:80%;"><p>可以看到确实有调用<code>pthread_mutex_lock/pthread_mutex_unlock</code>.</p><p>那么看一下一个典型的多线程程序(多个线程并发对全局变量执行自增操作, 用<code>mutex</code>保护该全局变量)的结果:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;threads.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;time.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;pthread.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> N 1000000</span></span><br><span class="line"><span class="keyword">volatile</span> <span class="keyword">long</span> sum = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">pthread_mutex_t</span> mutex = PTHREAD_MUTEX_INITIALIZER;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">do_sum</span><span class="params">(<span class="keyword">int</span> unused)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; ++i) &#123;</span><br><span class="line">        pthread_mutex_lock(&amp;mutex);</span><br><span class="line">        sum++;</span><br><span class="line">        pthread_mutex_unlock(&amp;mutex);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; ++i) &#123;</span><br><span class="line">        create(do_sum);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    join_all();</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;sum = %ld\n&quot;</span>, sum);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里使用了jyy提供的”threads.h”, 其实就是封装了一下<code>pthread</code>库, 用起来更简单些. <code>strace</code>的结果如下(<strong>注意需要使用<code>-f</code>选项</strong>):</p><img src="/2021/05/05/spin-mutex-futex/image-20210403220412333.png" alt="image-20210403220412333" style="zoom:80%;"><p>可以看到确实调用了<code>futex</code>, 并且每次调用的平均耗时为几十微秒:</p><img src="/2021/05/05/spin-mutex-futex/image-20210505093231322.png" alt="image-20210505093231322" style="zoom:67%;"><h3 id="GDB"><a href="#GDB" class="headerlink" title="GDB"></a>GDB</h3><h4 id="原始测试程序-单线程"><a href="#原始测试程序-单线程" class="headerlink" title="原始测试程序(单线程)"></a>原始测试程序(单线程)</h4><p>接下来使用gdb来调试一下原始那个测试程序. <strong>注意这个程序是单线程程序</strong>.</p><ol><li><p>单步调试进入<code>pthread_mutex_lock</code>函数. </p><img src="/2021/05/05/spin-mutex-futex/image-20210403221601612.png" alt="image-20210403221601612" style="zoom: 67%;"><p><code>lock cmpxchg</code>便是<code>spinlock</code>中提到的原子交换指令. </p></li><li><p>单步运行<code>si</code>:</p><img src="/2021/05/05/spin-mutex-futex/image-20210403221959408.png" alt="image-20210403221959408" style="zoom:67%;"><p>执行原子交换指令后, 下一条<code>je</code>指令判断成功, 跳转到目标处执行, 然后函数返回<code>retq</code>. 这种情况对于的是<code>pthread_mutex_lock</code>函数获取锁成功, 立即返回, <strong>可以看到没有执行任何系统调用</strong>(<code>syscall</code>).</p><p><strong>那如果获取失败呢?</strong> 可以从上图中看到<code>je</code>后面的第3条指令调用了<code>__lll_lock_wait</code>函数, 这个先不管它, 之后会调试.</p></li><li><p>单步调试进入<code>pthread_mutex_unlock</code>函数:</p><img src="/2021/05/05/spin-mutex-futex/image-20210403222933633.png" alt="image-20210403222933633" style="zoom:67%;"><p>可以看到这里的原子指令是 <strong><code>lock decl</code></strong>(相当于原子的自减操作), 而不是<code>lock cmpxchg</code>.</p></li><li><p>单步运行<code>si</code>:</p><img src="/2021/05/05/spin-mutex-futex/image-20210403223247470.png" alt="image-20210403223247470" style="zoom:67%;"><p>执行原子交换指令后, 下一条<code>je</code>指令判断成功, 跳转到目标处执行, 然后函数返回<code>retq</code>. 这种情况对于的是<code>pthread_mutex_unlock</code>函数解锁, 并且<strong>没有其他线程在等待这把锁</strong>, 立即返回, <strong>可以看到没有执行任何系统调用</strong>(<code>syscall</code>).</p><p><strong>如果<code>je</code>判断失败呢?</strong> 这对应的其实是释放锁时, <strong>有其他线程在等待这把锁</strong>, 所以要调用<code>__lll_unlock_wake</code>函数, 这里先不管它, 之后会调试.</p></li></ol><h4 id="典型多线程程序"><a href="#典型多线程程序" class="headerlink" title="典型多线程程序"></a>典型多线程程序</h4><p>现在调试一下典型多线程程序(即上面第2个程序). 为了方便调试, 只创建2个子线程(包括主线程, 总共有3个线程).</p><ol><li><p>在<code>do_sum</code>函数打断点, 运行, 然后<code>set scheduler-locking on</code>, 这个命令的作用是: 调试当前线程时, 让其他线程处于停止的状态.</p><img src="/2021/05/05/spin-mutex-futex/image-20210403224303366.png" alt="image-20210403224303366" style="zoom:67%;"></li><li><p>当前是 thread 2在运行, <code>LWP 26992</code>是该线程的ID, 之后会用到该ID. 先调试该线程. </p><p>进入<code>pthread_mutex_unlock</code>函数, 可以预料到它可以成功执行<code>pthread_mutex_lock</code>, 获取到全局变量<code>mutex</code>的所有权, 结果也确实如此:</p><p><img src="/2021/05/05/spin-mutex-futex/image-20210403224921759.png" alt="image-20210403224921759"></p><p><code>mutex</code>的<code>Owner ID</code>确实是 thread 2的ID, <code>mutex</code>的状态是**<code>Acquired, possibly with no waiters</code>**, 表示已经被上锁, 并且没有其他线程在等待该锁.</p></li><li><p>现在切换到 thread 3运行. 进入<code>pthread_mutex_lock</code>函数, 由于全局的锁<code>mutex</code>已经被 thread 2获取了, 可以预料到 <em><del>该函数调用将会失败</del></em> 原子交换指令将会发现”失败”:</p><img src="/2021/05/05/spin-mutex-futex/image-20210403225402579.png" alt="image-20210403225402579" style="zoom:67%;"><p>结果确实如此, <code>je</code>判断失败, 然后调用<code>__lll_lock_wait</code>函数.</p></li><li><p>进入<code>__lll_lock_wait</code>函数:</p><img src="/2021/05/05/spin-mutex-futex/image-20210403225715719.png" alt="image-20210403225715719" style="zoom:67%;"><p>可以看到确实执行了<code>syscall</code>指令, <code>0xca/202</code>是系统调用编号:</p><p><img src="/2021/05/05/spin-mutex-futex/image-20210403230018553.png" alt="image-20210403230018553"></p><p>确实是 <strong><code>futex</code></strong>! </p></li><li><p>这时 thread 3阻塞在获取<code>mutex</code>, 相当于进入了”睡眠”. </p><p>切换回 thread 2执行:</p><img src="/2021/05/05/spin-mutex-futex/image-20210403230903882.png" alt="image-20210403230903882" style="zoom:80%;"><p>此时<code>mutex</code>的状态是 <strong><code>Acquired, possibly with waiters</code></strong>, 表示有其他线程在等待获取该锁. </p></li><li><p>进入<code>pthread_mutex_lock</code>函数, 由于 thread 3此时正在等待这把锁, 可以预料到<code>lock decl</code>之后的判断将会失败:</p><img src="/2021/05/05/spin-mutex-futex/image-20210403231509194.png" alt="image-20210403231509194" style="zoom:67%;"><p>可以看到确实是这样.</p></li><li><p>进入<code>__lll_unlock_wake</code>函数:</p><img src="/2021/05/05/spin-mutex-futex/image-20210403231651108.png" alt="image-20210403231651108" style="zoom:67%;"><p>可以看到确实调用了<code>0xca</code>号系统调用, 即 <strong><code>futex</code></strong>!</p></li><li><p>切换回 thread 3, 由于 thread 2释放了<code>mutex</code>, 可以预料到 thread 3从<code>syscall</code>返回后会成功获取到<code>mutex</code>的所有权:</p><img src="/2021/05/05/spin-mutex-futex/image-20210403232133401.png" alt="image-20210403232133401" style="zoom: 80%;"><p><code>mutex</code>的<code>Owner ID</code>确实是 thread 3. 不过<code>mutex</code>的<code>status</code>有点诡异, 因为按理来说此时应该没有其他线程在等待该锁.</p></li></ol><h2 id="Futex"><a href="#Futex" class="headerlink" title="Futex"></a>Futex</h2><p>自行查阅<code>Linux man pages</code>: <strong><code>man futex</code></strong>.</p><h2 id="后语"><a href="#后语" class="headerlink" title="后语"></a>后语</h2><p>在最近的工作中, 使用了<code>libusb</code>库. 程序使用的是库推荐的<code>Asynchronous I/O</code>, 代码模式使用的也是文档的示例模式: 创建一个单独的线程, 不停的调用<code>libusb_handle_events</code>处理异步的事件. </p><p>查阅文档, 看到<code>libusb_handle_events</code>可以在多个线程中安全的使用, 因为它内部有一个<code>event_lock</code>. 但是我使用的程序中只用了一个线程调用<code>libusb_handle_events</code>来处理异步事件, 于是换成<code>libusb_handle_events_locked</code>接口, 省去额外的<code>lock/unlock</code>. 但是, 实际结果, 两种方式差别不大. 通过上文的分析, 该结果也不难理解.</p><p><del>此外, 在看<code>c++</code>的<code>std::shared_ptr</code>时, 我看到有的地方说<code>shared_ptr</code>内部的引用计数为了<code>thread-safety</code>, 有相应的锁保护, 如果过度使用它, 可能会有性能问题. 真的是这样吗? 有多大的性能下降?</del></p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;参考资料&lt;/strong&gt;: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://www.bilibili.com/video/BV1HN41197Ko?p=10&quot;&gt;2021 南京大学 “操作系统：设计与实现” (蒋</summary>
      
    
    
    
    <category term="NJU OS Lab" scheme="https://ysln.github.io/categories/NJU-OS-Lab/"/>
    
    
    <category term="C" scheme="https://ysln.github.io/tags/C/"/>
    
    <category term="thread" scheme="https://ysln.github.io/tags/thread/"/>
    
    <category term="mutex&amp;futex" scheme="https://ysln.github.io/tags/mutex-futex/"/>
    
    <category term="gdb" scheme="https://ysln.github.io/tags/gdb/"/>
    
    <category term="调试" scheme="https://ysln.github.io/tags/%E8%B0%83%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>硬件线程(hart)&amp;软件线程&amp;CPU</title>
    <link href="https://ysln.github.io/2021/05/05/threads-on-multi-CPU/"/>
    <id>https://ysln.github.io/2021/05/05/threads-on-multi-CPU/</id>
    <published>2021-05-05T01:02:36.051Z</published>
    <updated>2021-05-05T02:14:56.147Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><strong>参考资料</strong>:</p><ul><li><a href="http://jyywiki.cn/OS/2021/labs/L2">L2: 多处理器内核上的线程管理 (kmt) </a></li></ul><p>本文是在完成NJU操作系统实验过程中的一些记录.</p></blockquote><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>“多处理器内核上的线程管理 (kmt)”这个实验并不是很难, 前提是认真听了<a href="https://www.bilibili.com/video/BV1HN41197Ko?p=10">jyy的课</a>, 以及仔细阅读了jyy的实验指南. 由于没有认真听课, 所以做实验的时候踩了很多坑, 各种各样的并发bug, 虚拟机各种神秘重启.</p><p>这个实验和NJU”计算机系统基础”实验<a href="https://nju-projectn.github.io/ics-pa-gitbook/ics2020/3.2.html">PA3</a>&amp;<a href="https://nju-projectn.github.io/ics-pa-gitbook/ics2020/4.1.html">PA4</a><del>有点像</del>有点关联, 但两者侧重点不同. </p><ul><li>PA3&amp;PA4的侧重点是发生中断/异常时<code>context</code>的保存与恢复, 以及怎样创建内核线程(包括context的创建与放置, 如何跳转执行).  而且实验模拟的硬件是单CPU的.</li><li>这个实验中context的store/restore已经实现好了, 侧重点是多处理器内核上的线程管理, 关键词: <strong>多CPU</strong>, <strong>线程调度</strong>. </li></ul><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><h3 id="错误的尝试"><a href="#错误的尝试" class="headerlink" title="错误的尝试"></a>错误的尝试</h3><p>一开始, 我的做法是把所有的tasks(相当于线程)组织成一个链表, 用一把大锁(<code>spinlock</code>)保护这个链表. 然后调度发生时, 所有CPU都从这个链表取出可以运行的task执行. 按理来说这是最简单粗暴(但不好)的方法, 应该可以工作. 就像实现内存分配器一样, 先实现用一把大锁保护资源的方案, 然后去掉大锁, 换成CPU-local的方案.</p><p>当只创建一些执行简单代码的内核线程时(比如打印字符串), 看起来可以正常工作(好像偶尔还是会panic). 直到实现<code>semaphore</code>, 并创建生产者-消费者线程, 内核开始各种panic, 虚拟机各种神秘重启. 而且大多数情况下都是保护tasks链表的spinlock发生了错误: 同一个CPU重复对该spinlock上锁.</p><p>semaphore不同于spinlock, 当一个task获取spinlock失败时会一直”自旋”等待, 并不会让出CPU(<strong>关闭了中断</strong>). 但是当一个task对semaphore执行P操作失败时, 会把当前线程的状态置为SLEEPING, 表示当前task不能被调度执行, 然后执行<code>yield</code>, 主动让出CPU. 直到其他task对该semaphore执行V操作, 唤醒一个等待该semaphore的task. <strong>对semaphore执行V操作可以发生在任意地方, 包括中断处理程序里.</strong></p><p>问题就出现在<strong>所有CPU都对同一个tasks链表进行操作</strong>. <em>(我到现在也不知道到底是不是这个问题导致的).</em> 中断发生时(比如时钟中断), 就是线程调度的时刻. 而<strong>每个CPU都是独立响应中断的, 所以线程调度是并发的.</strong></p><p>我用尽了各种方法来调试这个问题, 包括gdb, 还是无法找出问题的关键. 当我被折磨得生不如死的时候, 我重新去看了jyy的课, 我确定了新的方案.</p><h3 id="有效方案"><a href="#有效方案" class="headerlink" title="有效方案"></a>有效方案</h3><p>把所有的tasks组织成一个链表看起来很简单, 但是<strong>有一个问题: 一个task有可能会被调度到任意一个CPU上去执行</strong>. 为什么不做的更简单彻底一点, 即: <strong>把task绑定到固定的CPU上.</strong></p><p>因此新的方案是: tasks链表实现成CPU-local的, 每个CPU只从自己的tasks链表中取出task来执行. 这样在调度发生时, CPU之间不需要争抢同一个spinlock, 效率更高. <em>即使这样, 每个CPU的tasks链表还是分别需要独立的spinlock保护起来</em>. </p><blockquote><p>关于CPU各自的tasks链表是否需要spinlock保护起来, 需要仔细考虑. 目前的使用场景下, 不需要, 因为在多处理器环境开启之前, 就由CPU0创建好了所有的tasks, 并把tasks分配到每个CPU上. 而且所有的task都不会返回, task不需要回收. 也就是说, 没有链表的插入节点与删除节点的操作.</p><p>当然, 使用spinlock也没有问题. 之后拓展使用场景时可能就需要spinlock, 比如: 运行时创建task, 销毁回收task, CPU之间的task迁移(负载均衡?).</p></blockquote><h3 id="坑"><a href="#坑" class="headerlink" title="坑"></a>坑</h3><p>下图截取自jyy的实验指南.</p><img src="/2021/05/05/threads-on-multi-CPU/image-20210504203105402.png" alt="image-20210504203105402" style="zoom:67%;"><p>jyy的代码实现很巧妙, 也很优雅. 但是有一点”误导”了我(我自己的锅, 理解有误). <code>os-&gt;on_irq</code>是用来注册中断处理函数的, 当中断/异常发生时, 便会根据发生的事件, 按序调用注册的handler function. </p><p><code>kmt_context_save</code>这个函数的名字让我产生了误解. save的是context这个结构体呢? 还是context指针? 其实这里的语义是<strong>把已经保存在当前task的内核栈上的context的地址/指针, 保存在该task相关的数据结构里面</strong>. 这里<code>kemt_context_save</code>和<code>kmt_schedule</code>分开来了, 并且 <code>kemt_context_save</code>总是<strong>最先</strong>调用, <code>kmt_schedule</code>总是<strong>最后</strong>调用. 之前做”计算机系统基础”实验<a href="https://nju-projectn.github.io/ics-pa-gitbook/ics2020/3.2.html">PA3</a>时, 我把两部分都放在了调度函数(类似于<code>kmt_schedule</code>)里面. 按照正常的逻辑来说, 两种做法其实是等价的.</p><p><strong>那什么是非正常的逻辑? 在handler function(比如时钟/键盘中断处理函数)里面调用<code>yield</code></strong>. 为了方便描述, 假设:</p><ol><li>方案A: <code>kemt_context_save</code>和<code>kmt_schedule</code>分开, 两者之间可以调用任意的handler function.</li><li>方案B: <code>kemt_context_save</code>合并进<code>kmt_schedule</code>里面, 相当于两者是原子的, 所有的handler function调用完毕才会调用<code>kmt_schedule</code>.</li></ol><p>哪一种方案在这种特殊/非正常情景下有问题? </p><p><code>schedule</code>的功能大致如下:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Context *<span class="title">schedule</span><span class="params">(Event ev, Context *ctx)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 方案B等价于在这里调用yield</span></span><br><span class="line">   </span><br><span class="line">  current_task-&gt;context = ctx;  <span class="comment">// (1) 保存context指针</span></span><br><span class="line">   </span><br><span class="line">  <span class="comment">// 方案A等价于在这里调用yield</span></span><br><span class="line">    </span><br><span class="line">  current_task = select_next_task();  <span class="comment">// (2) 选择一个可运行的task</span></span><br><span class="line">    </span><br><span class="line">  <span class="keyword">return</span> current_task-&gt;context;  <span class="comment">// 之后的代码会把选中的task的context恢复到当前CPU上</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>方案A等价于在上述代码第6行中调用了<code>yield</code>, 此时又会引发新的一轮context的store/restore: </p><img src="/2021/05/05/threads-on-multi-CPU/image-20210504215901784.png" alt="image-20210504215901784" style="zoom: 67%;"><p>当<code>yield</code>返回时(<strong>某次调度发生时, 选择了该task运行, 此时表明ctx 2已经从该task的内核栈上销毁</strong>), <code>curr-&gt;ctx</code>并没有得到更新: 应该指向ctx 1, 但还是指向<code>yield</code>发生时, 保存到栈上的context(即ctx 2), 但到当前这个时刻ctx 2指向的区域是无效的.</p><p>而方案B没有以上问题, 因为传递给<code>schedule</code>函数的<code>ctx</code>参数是保存在该task的内核栈上的(即上图中的stack variable区域, 每个保存在栈上的context后面都会有), 栈上变量在函数的作用域内是有效的, 这是由C语言的机制保证的, <code>ctx</code>参数总是指向最近一次保存在内核栈上的context的地址.</p><h2 id="延申思考"><a href="#延申思考" class="headerlink" title="延申思考"></a>延申思考</h2><h3 id="idle-task"><a href="#idle-task" class="headerlink" title="idle task"></a>idle task</h3><p>之前在看Linux内核相关的资料时, 好像在哪看到了idle task这个说法, 一直没有理解这是个啥. 做完这个实验, 我好像有点懂了. <em>以下是个人理解.</em></p><p>以前玩单片机时, 程序里先是注册各种中断处理程序, 在最后面总是要加上 <code>while (1);</code>, 然后就开始响应各种中断. 这里的 <code>while (1);</code>其实就可以理解成idle task. CPU总是要干点什么, 即使只是死循环, 不然它就直接shutdown了.</p><p>操作系统代码也是一样, 在把所有资源初始化好之后, 它就退变为一个<strong>中断响应程序</strong>. 因此, 它也需要一个idle task, 以防止CPU shutdown. 当没有可运行的task可以调度执行时, 总是需要调度idle task到CPU上执行.</p><img src="/2021/05/05/threads-on-multi-CPU/image-20210504154530774.png" alt="image-20210504154530774" style="zoom:67%;"><h3 id="中断处理函数里不能休眠"><a href="#中断处理函数里不能休眠" class="headerlink" title="中断处理函数里不能休眠"></a>中断处理函数里不能休眠</h3><p>之前在看”Linux内核设计与实现”这本书时, 里面提到不能在中断上下文中调用会引起睡眠/阻塞的函数: <em>中断上下文和进程并没有什么瓜葛. 与current宏也是不相干的(尽管它会指向被中断的进程). 因为没有后备进程, 所以中断上下文不可以睡眠, 否则怎能再对它重新调度呢?</em></p><p>我不太清楚Linux内核关于context的store/restore, 所以对这句话不是很理解.</p><p>根据我做完实验的理解, 睡眠即相当于主动调用<code>yield</code>, 让出CPU的执行权. 上文也分析了, 在当前的代码实现中, 在中断处理程序(handler function)里面调用<code>yield</code>, 根据实验现象来看, 无论是单CPU还是多CPU都是没有什么问题的. 还需要仔细思考这个问题.</p><h3 id="操作系统是一个并发程序"><a href="#操作系统是一个并发程序" class="headerlink" title="操作系统是一个并发程序"></a>操作系统是一个并发程序</h3><p>jyy在上课时总是在说这句话, 而且在课程安排上, 花了很多时间来讲并发, 和一些看起来和写操作系统代码无关的东西. 做完这个实验, 我又懂了.</p><p>当使用比如<code>POSIX threads</code>API创建线程时, 我们知道线程创建之后就会开始并发执行, 并且所有线程共享同一地址空间的全部内容, 比如全局/静态的数据. 每个线程都可以访问并修改全局变量, 并且修改后对其他线程也是可见的. 因此, 我们知道对于对于共享的数据, 需要使用锁保护起来, 比如<code>mutex</code>来提供互斥.</p><p>把视角切换回操作系统内核. CPU可以想象成上面提到的”线程”, 而操作系统内核代码可以想象成我们写的多线程程序. 因此, 所有的CPU执行的都是同一份代码, 代码里面所有的全局/静态数据, CPU都可以访问/修改, 并且修改后CPU之间也是可见的. 所以操作系统的代码里同样需要锁来保护共享的数据.</p><p>比如xv6的这段代码:</p><img src="/2021/05/05/threads-on-multi-CPU/image-20210504161404905.png" alt="image-20210504161404905" style="zoom:67%;"><p>CPU编号为0的CPU会执行<code>if</code>分支的代码, 其他所有的CPU执行<code>else</code>分支的代码. 由于内核里所有的全局数据都是共享的(比如文件系统相关的资源, 进程表等), 所以只需要由CPU0来初始化一次(当然可以由任意一个CPU来完成这个工作).   如果你足够细心, 你会发现上图中<code>else</code>分支里调用的函数都有<code>hart</code>后缀. 另外, 这里的<code>scheduler</code>也起到了前面提到的idle task的作用.</p><h3 id="硬件线程-hart"><a href="#硬件线程-hart" class="headerlink" title="硬件线程(hart)"></a>硬件线程(hart)</h3><p>通过阅读RISC-V的手册, 我得到了以下信息:</p><blockquote><p>hart是硬件线程(hardware thread)的缩略形式. 我们用该术语将它们与大多数程序员熟悉的软件线程区分开来. 软件线程在harts上进行分时复用. 大多数处理器核都只有一个hart.</p></blockquote><p>简单理解, 一个CPU <em>(我不太理解CPU与CPU core的区别, 这里把它们都称作CPU)</em> 就是一个硬件线程(hart), 用户/内核创建的一个软件线程, 对应的就是CPU-local的tasks链表中的一个task.</p><p>此外, 我又想到了AMD的<del>县城</del>线程撕裂者:</p><img src="/2021/05/05/threads-on-multi-CPU/image-20210504164349104.png" alt="image-20210504164349104" style="zoom:67%;">]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;参考资料&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://jyywiki.cn/OS/2021/labs/L2&quot;&gt;L2: 多处理器内核上的线程管理 (kmt) &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本文</summary>
      
    
    
    
    <category term="NJU OS Lab" scheme="https://ysln.github.io/categories/NJU-OS-Lab/"/>
    
    
    <category term="C" scheme="https://ysln.github.io/tags/C/"/>
    
    <category term="OS" scheme="https://ysln.github.io/tags/OS/"/>
    
    <category term="thread" scheme="https://ysln.github.io/tags/thread/"/>
    
    <category term="hart" scheme="https://ysln.github.io/tags/hart/"/>
    
  </entry>
  
  <entry>
    <title>C语言实现Real-Eval-Print-Loop (REPL)</title>
    <link href="https://ysln.github.io/2021/05/01/crepl/"/>
    <id>https://ysln.github.io/2021/05/01/crepl/</id>
    <published>2021-05-01T07:11:46.598Z</published>
    <updated>2021-05-05T01:13:15.097Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><strong>参考资料</strong>: </p><ul><li><a href="http://jyywiki.cn/OS/2021/labs/M4">M4: C Real-Eval-Print-Loop (crepl)</a></li></ul><p>本文是在完成NJU操作系统实验过程中的一些记录.</p></blockquote><p>很多现代编程语言都提供了交互式的REPL, 比如Python这种”解释执行”的语言. 在REPL中, 除了进行简单的数值计算外(类似计算器), 还可以动态创建函数, 并在之后调用它. </p><p>这个实验的目的是使用C语言实现一个简易的REPL. 最终效果如下:</p><img src="/2021/05/01/crepl/image-20210501112153656.png" alt="image-20210501112153656" style="zoom: 67%;"><p><em><strong>这个技术和现代虚拟机中的即时编译 (just-in-time) 技术是非常相关的：在程序运行时 (而非程序执行前) 进行编译，并将编译得到的二进制代码 (指令/数据) 动态加载。</strong></em> — 摘自<a href="http://jyywiki.cn/OS/2021/labs/M4">jyy的实验指南</a>.</p><h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>C语言是一种编译型的语言, 源文件到二进制文件需要经过编译和链接(link)两个过程. 链接主要完成的工作是<strong>符号解析</strong>和<strong>重定位</strong>. </p><p>如果是静态链接的程序(<code>-static</code>), 类型为”Executable file(EXEC)”,  即<strong>可执行文件</strong>. 程序中的所有符号都是被完全解析的, 比如所有函数符号的地址都是确定的, 可以直接调用.</p><p>GCC默认生成的二进制文件是动态链接的,  生成的文件文件类型为”Shared object file(DYN)”. 一个动态链接的程序从磁盘(disk)上刚加载出来时是 <strong>不完整(部分链接)</strong> 的, 比如程序调用的位于glibc动态链接库中的<code>printf</code>函数地址是未知的. 内核(加载器)不能立即把控制权交给该程序(即跳转到<code>entry</code>). 因此, 需要另外的辅助程序(helper program)的帮助 ——– <strong>dynamic linker</strong>, (一般是ld.so). 它的任务是: <strong>加载程序依赖的DSOs(动态链接库, 比如glibc), 并完成重定位(<code>relocation</code>)</strong>.</p><p>因此, 要想实现一个交互式的REPL, 在程序运行时动态的在其地址空间内加入新的函数符号, 本质上是实现动态链接器的功能.</p><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>C语言实现的REPL的工作流程如下:</p><ol><li>读取用户的输入.</li><li>把输入的内容写入一个临时的源文件, 并把其编译成一个动态链接库.</li><li>把动态链接库加载到进程的地址空间.</li><li>计算用户输入的表达式, 输出结果.</li><li>重复上述步骤.</li></ol><h3 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h3><img src="/2021/05/01/crepl/image-20210504125129936.png" alt="image-20210504125129936" style="zoom:67%;"><p>这里有以下注意事项:</p><ul><li><p>如果用户输入不是函数, 而是表达式, 比如”5 + 6”, 该怎么办? 一个很自然(看完jyy的实验指南后确实很自然…)的想法是把表达式”包装(wrap)”成一个函数, 比如:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> __wrap_func() &#123; <span class="keyword">return</span> <span class="number">5</span> + <span class="number">6</span>;&#125;</span><br></pre></td></tr></table></figure></li><li><p>这里实现”即时编译”的方法是<code>fork</code>一个子进程, 让子进程执行GCC, 主要是<code>exec</code>函数族(l, v, p, e的组合)的使用, 要注意<code>argv[0]</code>需要为可执行文件的名字.  注意这里把子进程的标准输出和标错误都关闭了, 防止gcc的输出影响.</p><p>这里还有一点是如果用户输入”f() + 6”, 那么源文件的内容为:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> __wrap_func() &#123; <span class="keyword">return</span> f() + <span class="number">6</span>;&#125;</span><br></pre></td></tr></table></figure><p>此时gcc编译会给出警告: “f”未定义. 如果”f”在之前定义了, 那么这个警告就无关紧要. 就算”f”没有定义, 也没有关系, 可以把出错处理推迟到加载阶段.</p></li></ul><h3 id="加载"><a href="#加载" class="headerlink" title="加载"></a>加载</h3><img src="/2021/05/01/crepl/image-20210501130905417.png" alt="image-20210501130905417" style="zoom:67%;"><p>可以使用<code>dlopen</code>在运行时加载一个so文件到当前进程的地址空间中. 这里需要注意<code>dlopen</code>的flag参数:</p><ul><li><p><code>RTLD_GLOBAL</code>是必不可少的, 其含义是: 当前加载的so中的符号对其他so可见, 也就是说之后加载的so符号解析时, 可以使用这个so中的符号. 与其相对的是<code>RTLD_LOCAL</code>. 如果去掉<code>RTLD_GLOBAL</code>, 会出现以下这种情况:</p><img src="/2021/05/01/crepl/image-20210501131258559.png" alt="image-20210501131258559" style="zoom:67%;"><p>注意表达式”f()”也会被”wrap”成一个函数, 并编译成so. </p></li><li><p><code>RTLD_NOW</code>也是必不可少的, 其含义是: 在加载so时就进行(函数)符号解析. 与之相对的是<code>RTLD_LAZY</code>, 表示对应的函数符号解析推迟到函数被调用时. </p><p>使用<code>RTLD_LAZY</code>参数有以下实验现象:</p><img src="/2021/05/01/crepl/image-20210501132200769.png" alt="image-20210501132200769" style="zoom:67%;"><img src="/2021/05/01/crepl/image-20210504122855560.png" alt="image-20210504122855560" style="zoom:67%;"><p>也就是说, 定义函数时<strong>可以</strong>使用<strong>当前还未定义</strong>的符号, <code>dlopen</code>时不会报错(因为不会进行符号解析). 但是调用时如果找不到对应的函数符号, 进程会直接crash, 结束运行.</p><p>而使用<code>RTLD_NOW</code>参数有以下实验现象:</p><img src="/2021/05/01/crepl/image-20210501132836648.png" alt="image-20210501132836648" style="zoom:67%;"><p>也就是说定义函数时<strong>不允许</strong>使用<strong>当前还未定义</strong>的符号, 也不能直接使用未定义的函数计算,  <code>dlopen</code>进行符号解析时就会出错. 因此, 这才是我们想要的行为.</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;参考资料&lt;/strong&gt;: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://jyywiki.cn/OS/2021/labs/M4&quot;&gt;M4: C Real-Eval-Print-Loop (crepl)&lt;/a&gt;&lt;/li&gt;</summary>
      
    
    
    
    <category term="NJU OS Lab" scheme="https://ysln.github.io/categories/NJU-OS-Lab/"/>
    
    
    <category term="C" scheme="https://ysln.github.io/tags/C/"/>
    
    <category term="REPL" scheme="https://ysln.github.io/tags/REPL/"/>
    
    <category term="动态链接" scheme="https://ysln.github.io/tags/%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5/"/>
    
  </entry>
  
</feed>
